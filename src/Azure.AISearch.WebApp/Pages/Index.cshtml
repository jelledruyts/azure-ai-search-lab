@page
@model IndexModel
@{
    ViewData["Title"] = "Search";
}
@section Scripts {
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: false });

        const { createApp, ref, watch } = Vue
        createApp({
            setup() {
                const scenarios = ref(@Html.Raw(JsonSerializer.Serialize(Model.Scenarios, JsonConfiguration.DefaultJsonOptions)));
                const selectedScenario = ref(null);
                const searchRequest = ref(@Html.Raw(JsonSerializer.Serialize(Model.SearchRequest, JsonConfiguration.DefaultJsonOptions)));
                var settingsValue = { showExplanation: true };
                var settingsValueStorage = localStorage.getItem('settings');
                if (settingsValueStorage) {
                    settingsValue = JSON.parse(settingsValueStorage);
                }
                const settings = ref(settingsValue);

                // Update the search request when a scenario is selected.
                watch(selectedScenario, (newScenario) => {
                    if (newScenario) {
                        searchRequest.value = newScenario.searchRequest;
                    }
                });

                // Save settings when changed.
                watch(settings, (newSettings) => {
                    localStorage.setItem('settings', JSON.stringify(newSettings));
                }, { deep: true });

                // Update the sequence diagram whenever relevant properties change.
                watch(
                    () => [settings.value.showExplanation, searchRequest.value.engine, searchRequest.value.searchIndex, searchRequest.value.queryType, searchRequest.value.dataSource],
                    () => showSequenceDiagram()
                );

                const drawMermaid = function (mermaidDiagram) {
                    const currentTheme = document.documentElement.getAttribute('data-bs-theme');
                    const mermaidTheme = currentTheme == 'dark' ? 'dark' : 'default';
                    const graphDefinition = "%%{init: {'theme':'" + mermaidTheme + "'}}%%" + mermaidDiagram;
                    mermaid.render('mermaidSvg', graphDefinition).then(({ svg, bindFunctions }) => {
                        const mermaidElement = document.getElementById('mermaid');
                        mermaidElement.innerHTML = svg;
                    });
                };

                const getAzureCognitiveSearchSequenceDiagram = function (sourceParticipant, queryType, searchIndex) {
                    var mermaidDiagram = '';
                    mermaidDiagram += 'create participant ACS as Azure Cognitive Search\n';
                    if (queryType == '@QueryType.TextStandard' || queryType == '@QueryType.TextSemantic') {
                        // Pure text search.
                        mermaidDiagram += `${sourceParticipant}->>ACS: Search using text\n`;
                        mermaidDiagram += `create participant Index as ${searchIndex} Index\n`;
                        mermaidDiagram += `ACS->>Index: Search using text\n`;
                        mermaidDiagram += 'destroy Index\n';
                        mermaidDiagram += 'Index-xACS: Text search results\n';
                    }
                    else if (queryType == '@QueryType.Vector') {
                        // Pure vector search.
                        mermaidDiagram += `${sourceParticipant}->>ACS: Search using vector\n`;
                        mermaidDiagram += `create participant Index as ${searchIndex} Index\n`;
                        mermaidDiagram += `ACS->>Index: Search using vector\n`;
                        mermaidDiagram += 'destroy Index\n';
                        mermaidDiagram += 'Index-xACS: Vector search results\n';
                    }
                    else if (queryType == '@QueryType.HybridStandard' || queryType == '@QueryType.HybridSemantic') {
                        // Hybrid search.
                        mermaidDiagram += `${sourceParticipant}->>ACS: Search using vector and text\n`;
                        mermaidDiagram += `create participant Index as ${searchIndex} Index\n`;
                        mermaidDiagram += `ACS->>Index: Search using vector\n`;
                        mermaidDiagram += 'Index->>ACS: Vector search results\n';
                        mermaidDiagram += `ACS->>Index: Search using text\n`;
                        mermaidDiagram += 'destroy Index\n';
                        mermaidDiagram += 'Index-xACS: Text search results\n';
                        mermaidDiagram += `ACS->>ACS: Merge (rerank) vector and text search results\n`;
                    }

                    if (queryType == '@QueryType.TextSemantic' || queryType == '@QueryType.HybridSemantic') {
                        // Semantic search.
                        mermaidDiagram += 'ACS->>ACS: L2 semantic reranking of search results\n';
                    }
                    mermaidDiagram += 'destroy ACS\n';
                    mermaidDiagram += `ACS-x${sourceParticipant}: Search results\n`;
                    return mermaidDiagram;
                }

                const getAzureOpenAIVectorSequenceDiagram = function () {
                    var mermaidDiagram = '';
                    mermaidDiagram += 'create participant Embedding as Embedding Model\n';
                    mermaidDiagram += 'AOAI->>Embedding: Generate vector for search query\n';
                    mermaidDiagram += 'destroy Embedding\n';
                    mermaidDiagram += 'Embedding-xAOAI: Vector for search query\n';
                    return mermaidDiagram;
                }

                const showSequenceDiagram = function () {
                    if (!settings.value.showExplanation) {
                        return;
                    }
                    var engine = searchRequest.value.engine;
                    var searchIndex = searchRequest.value.searchIndex;
                    var dataSource = searchRequest.value.dataSource;
                    var queryType = searchRequest.value.queryType;
                    var needsVector = (queryType == '@QueryType.Vector' || queryType == '@QueryType.HybridStandard' || queryType == '@QueryType.HybridSemantic');

                    var mermaidDiagram = 'sequenceDiagram\n';
                    mermaidDiagram += 'actor User as User\n';
                    mermaidDiagram += 'participant App as Search App\n';
                    if (engine == '@EngineType.AzureCognitiveSearch') {
                        // Azure Cognitive Search.
                        mermaidDiagram += 'User->>App: Search query\n';
                        if (needsVector) {
                            mermaidDiagram += 'create participant AOAI as Azure OpenAI\n';
                            mermaidDiagram += 'App->>AOAI: Generate vector for search query\n';
                            mermaidDiagram += getAzureOpenAIVectorSequenceDiagram();
                            mermaidDiagram += 'destroy AOAI\n';
                            mermaidDiagram += 'AOAI-xApp: Vector for search query\n';
                        }
                        mermaidDiagram += getAzureCognitiveSearchSequenceDiagram('App', queryType, searchIndex);
                        mermaidDiagram += 'App->>User: Search results\n';
                    } else if (engine == '@EngineType.AzureOpenAI') {
                        // Azure OpenAI.
                        mermaidDiagram += 'User->>App: Search query and history\n';
                        mermaidDiagram += 'create participant AOAI as Azure OpenAI\n';
                        mermaidDiagram += 'App->>AOAI: Generate chat response\n';
                        if (dataSource == '@DataSourceType.AzureCognitiveSearch') {
                            // Using data source Azure Cognitive Search.
                            if (needsVector) {
                                mermaidDiagram += getAzureOpenAIVectorSequenceDiagram();
                            }
                            mermaidDiagram += getAzureCognitiveSearchSequenceDiagram('AOAI', queryType, searchIndex);
                            mermaidDiagram += 'AOAI->>AOAI: Build a prompt using the search results to ground the model\n';
                        }
                        // Chat completion.
                        mermaidDiagram += 'create participant GPT as GPT Model\n';
                        var gptInput = dataSource == '@DataSourceType.None' ? 'Generate chat response using search query and history' : 'Generate chat response using specialized prompt';
                        mermaidDiagram += `AOAI->>GPT: ${gptInput}\n`;
                        mermaidDiagram += 'destroy GPT\n';
                        mermaidDiagram += 'GPT-xAOAI: Chat response\n';
                        mermaidDiagram += 'destroy AOAI\n';
                        mermaidDiagram += 'AOAI-xApp: Chat response\n';
                        mermaidDiagram += 'App->>User: Chat response\n';
                    } else if (engine == '@EngineType.CustomOrchestration') {
                        // Custom orchestration.
                        mermaidDiagram += 'User->>App: Search query\n';
                        mermaidDiagram += 'create participant AOAI as Azure OpenAI\n';
                        if (needsVector) {
                            mermaidDiagram += 'App->>AOAI: Generate vector for search query\n';
                            mermaidDiagram += getAzureOpenAIVectorSequenceDiagram();
                            mermaidDiagram += 'AOAI->>App: Vector for search query\n';
                        }
                        mermaidDiagram += getAzureCognitiveSearchSequenceDiagram('App', queryType, searchIndex);
                        mermaidDiagram += 'App->>App: Build a prompt using the search results to ground the model\n';
                        mermaidDiagram += `App->>AOAI: Generate chat response\n`;
                        mermaidDiagram += 'create participant GPT as GPT Model\n';
                        mermaidDiagram += `AOAI->>GPT: Generate chat response using specialized prompt\n`;
                        mermaidDiagram += 'destroy GPT\n';
                        mermaidDiagram += 'GPT-xAOAI: Chat response\n';
                        mermaidDiagram += 'destroy AOAI\n';
                        mermaidDiagram += 'AOAI-xApp: Chat response\n';
                        mermaidDiagram += 'App->>User: Chat response\n';
                    }

                    drawMermaid(mermaidDiagram);
                };

                showSequenceDiagram();

                return {
                    scenarios, selectedScenario, searchRequest, settings
                };
            }
        }).mount('#app');

        // Enable popovers after the Vue app is mounted as the trigger elements are dynamically added to the DOM. 
        const popoverTriggerList = document.querySelectorAll('[data-bs-toggle="popover"]');
        const popoverList = [...popoverTriggerList].map(popoverTriggerEl => new bootstrap.Popover(popoverTriggerEl, { html: true }));
    </script>
}
<h2 class="display-6 mb-3">@ViewData["Title"]</h2>

<form method="post" class="mb-3">

    <div class="card mb-3">
        <div class="card-header">Options</div>
        <div class="card-body">
            <div class="mb-2">
                <label class="form-label">Predefined scenario</label>
                <div class="form-group">
                    <select class="form-select" v-model="selectedScenario">
                        <option v-bind:value="null">None</option>
                        <option v-for="scenario in scenarios" v-bind:value="scenario">{{ scenario.displayName }}</option>
                    </select>
                </div>
                <div class="alert alert-primary mt-2" v-if="selectedScenario && selectedScenario.description">
                    {{ selectedScenario.description }}
                </div>
            </div>
            <div class="mb-2">
                <label class="form-label">Engine</label>
                <div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.Engine)" id="searchRequest-Engine-AzureCognitiveSearch" value="@EngineType.AzureCognitiveSearch" v-model="searchRequest.engine">
                        <label class="form-check-label" for="searchRequest-Engine-AzureCognitiveSearch">Azure Cognitive Search</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Search through content with <a href='https://learn.microsoft.com/azure/search/search-what-is-azure-search' target='_blank'>Azure Cognitive Search</a>. You can use <a href='https://learn.microsoft.com/azure/search/search-lucene-query-architecture' target='_blank'>full-text</a> and optionally <a href='https://learn.microsoft.com/azure/search/vector-search-overview' target='_blank'>vector-based</a> queries. The responses <i>always</i> come directly from the source data, rather than being generated by an AI model. You can optionally enable <a href='https://learn.microsoft.com/azure/search/semantic-search-overview' target='_blank'>semantic search</a> which <i>does</i> use AI, not to generate content but to increase the relevancy of the results."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.Engine)" id="searchRequest-Engine-AzureOpenAI" value="@EngineType.AzureOpenAI" v-model="searchRequest.engine">
                        <label class="form-check-label" for="searchRequest-Engine-AzureOpenAI">Azure OpenAI</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Use a <a href='https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt' target='_blank'>GPT model</a> in <a href='https://learn.microsoft.com/azure/ai-services/openai/overview' target='_blank'>Azure OpenAI</a> to perform a chat-based search experience. The responses are AI-generated rather than taken directly from the source data. When using <a href='https://learn.microsoft.com/azure/ai-services/openai/concepts/use-your-data' target='_blank'>Azure OpenAI on your data</a>, the responses can be grounded in (and even limited to) the information in a private data source."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.Engine)" id="searchRequest-Engine-CustomOrchestration" value="@EngineType.CustomOrchestration" v-model="searchRequest.engine">
                        <label class="form-check-label" for="searchRequest-Engine-CustomOrchestration">Custom orchestration</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Use custom orchestration to perform the <a href='https://aka.ms/what-is-rag' target='_blank'>Retrieval Augmented Generation (RAG)</a> pattern. This is using <a href='https://learn.microsoft.com/semantic-kernel/overview/' target='_blank'>Semantic Kernel</a> behind the scenes to first retrieve relevant search results from Azure Cognitive Search, and then build a prompt with those search results along with the original query to generate an answer (with citations)."><i class="bi bi-info-circle"></i></span>
                    </div>
                </div>
            </div>

            <div class="mb-2" v-show="searchRequest.engine == '@EngineType.AzureOpenAI' || searchRequest.engine == '@EngineType.CustomOrchestration'">
                <label class="form-label" for="searchRequest-SystemRoleInformation">GPT model deployment</label>
                <span class="info-tip" data-bs-toggle="popover" data-bs-content="If you deployed other models (or versions) to Azure OpenAI than the default one, specify the deployment name here to use that instead."><i class="bi bi-info-circle"></i></span>
                <input type="text" class="form-control" name="@nameof(SearchRequest.OpenAIGptDeployment)" id="searchRequest-OpenAIGptDeployment" v-model="searchRequest.openAIGptDeployment">
            </div>

            <div class="mb-2" v-show="searchRequest.engine == '@EngineType.AzureOpenAI'">
                <label class="form-label" for="searchRequest-SystemRoleInformation">System role information</label>
                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Give the model instructions about how it should behave and any context it should reference when generating a response. You can describe the assistant's personality, tell it what it should and shouldn't answer, and tell it how to format responses."><i class="bi bi-info-circle"></i></span>
                <input type="text" class="form-control" name="@nameof(SearchRequest.SystemRoleInformation)" id="searchRequest-SystemRoleInformation" v-model="searchRequest.systemRoleInformation">
            </div>

            <div class="mb-2" v-show="searchRequest.engine == '@EngineType.CustomOrchestration'">
                <label class="form-label" for="searchRequest-SystemRoleInformation">Prompt template</label>
                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Define the prompt that will be sent to the AI model. Use <code>{{$query}}</code> to refer to the original query and <code>{{$sources}}</code> to refer to the relevant data sources as retrieved from Azure Cognitive Search."><i class="bi bi-info-circle"></i></span>
                <textarea class="form-control" name="@nameof(SearchRequest.CustomOrchestrationPrompt)" id="searchRequest-CustomOrchestrationPrompt" v-model="searchRequest.customOrchestrationPrompt" rows="10"></textarea>
            </div>

            <div class="mb-2" v-show="searchRequest.engine == '@EngineType.AzureOpenAI'">
                <label class="form-label">Data source (Azure OpenAI &quot;on your data&quot;)</label>
                <span class="info-tip" data-bs-toggle="popover" data-bs-content="When using a private data source, <a href='https://learn.microsoft.com/azure/ai-services/openai/concepts/use-your-data' target='_blank'>Azure OpenAI on your data</a> orchestrates the <a href='https://aka.ms/what-is-rag' target='_blank'>Retrieval Augmented Generation (RAG)</a> pattern. This means your search query will first be used to retrieve the most relevant documents (or preferably <i>smaller chunks of those documents</i>) from your private data source. Those search results are then used as context in the prompt that gets sent to the AI model, along with the original search query. This allows the AI model to generate a response based on the most relevant source data, rather than the public data that was used to train the model."><i class="bi bi-info-circle"></i></span>
                <div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.DataSource)" id="searchRequest-DataSource-None" value="@DataSourceType.None" v-model="searchRequest.dataSource">
                        <label class="form-check-label" for="searchRequest-DataSource-None">None</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Don't use a private data source, let the AI model respond using only the data it was trained on."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.DataSource)" id="searchRequest-DataSource-AzureCognitiveSearch" value="@DataSourceType.AzureCognitiveSearch" v-model="searchRequest.dataSource">
                        <label class="form-check-label" for="searchRequest-DataSource-AzureCognitiveSearch">Azure Cognitive Search</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Use source data from an Azure Cognitive Search index. For best results, you should use the <code>Chunks</code> index, as this contains smaller and typically more contextually relevant pieces of information. This makes the prompt that is sent to the AI model better suited to generate a meaningful response from."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline form-switch">
                        <input class="form-check-input" type="checkbox" role="switch" name="@nameof(SearchRequest.LimitToDataSource)" id="searchRequest-LimitToDataSource" value="true" v-model="searchRequest.limitToDataSource" v-bind:disabled="searchRequest.dataSource == '@DataSourceType.None'">
                        <input type="hidden" name="@nameof(SearchRequest.LimitToDataSource)" value="false" />
                        <label class="form-check-label" for="searchRequest-LimitToDataSource">Limit to your data</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Limit responses to your data content only, not including the data that was used for training the model."><i class="bi bi-info-circle"></i></span>
                    </div>
                </div>
            </div>

            <div class="mb-2" v-show="!(searchRequest.engine == '@EngineType.AzureOpenAI' && searchRequest.dataSource == '@DataSourceType.None')">
                <label class="form-label">Search index</label>
                <div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.SearchIndex)" id="searchRequest-SearchIndex-Documents" value="@SearchIndexType.Documents" v-model="searchRequest.searchIndex">
                        <label class="form-check-label" for="searchRequest-SearchIndex-Documents">Documents</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Contains the full text content of the source data, as <a href='https://learn.microsoft.com/azure/search/search-blob-storage-integration' target='_blank'>extracted from your files in Blob storage</a>. Each file and its entire contents are stored as a single document in the search index, which can therefore be quite large. For regular text or semantic search that works great, but large content may cause issues with token limits, prompt size and content relevancy in AI applications."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.SearchIndex)" id="searchRequest-SearchIndex-Chunks" value="@SearchIndexType.Chunks" v-model="searchRequest.searchIndex">
                        <label class="form-check-label" for="searchRequest-SearchIndex-Chunks">Chunks</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Each file in the <code>Documents</code> index is automatically processed by an <a href='https://learn.microsoft.com/azure/search/cognitive-search-working-with-skillsets' target='_blank'>Azure Cognitive Search skillset</a>. This splits it into smaller pieces (chunks) and then uses an <a href='https://learn.microsoft.com/azure/ai-services/openai/how-to/embeddings' target='_blank'>embedding model in Azure OpenAI</a> to generate a vector representation of that piece of content. Each chunk's content and this vector are then stored as a separate document in the search index. This makes it much better suited to find the most relevant piece of content by using <a href='https://learn.microsoft.com/azure/search/vector-search-overview' target='_blank'>vector (or hybrid) search</a> search, and reduces the content size to make an AI prompt fit within token limits."><i class="bi bi-info-circle"></i></span>
                    </div>
                </div>
            </div>

            <div class="mb-2" v-show="!(searchRequest.engine == '@EngineType.AzureOpenAI' && searchRequest.dataSource == '@DataSourceType.None')">
                <label class="form-label">Query type</label>
                <div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.QueryType)" id="searchRequest-QueryType-TextStandard" value="@QueryType.TextStandard" v-model="searchRequest.queryType">
                        <label class="form-check-label" for="searchRequest-QueryType-TextStandard">Standard text</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Use regular <a href='https://learn.microsoft.com/azure/search/search-lucene-query-architecture' target='_blank'>full-text search</a>."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.QueryType)" id="searchRequest-QueryType-TextSemantic" value="@QueryType.TextSemantic" v-model="searchRequest.queryType">
                        <label class="form-check-label" for="searchRequest-QueryType-TextSemantic">Semantic text</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Use <a href='https://learn.microsoft.com/azure/search/semantic-search-overview' target='_blank'>semantic search</a>, which returns more relevant results by applying language understanding to initial search results. It can also return <a href='https://learn.microsoft.com/azure/search/semantic-how-to-query-request' target='_blank'>semantic captions</a> (parts of a document that best summarize the content) and even <a href='https://learn.microsoft.com/azure/search/semantic-answers' target='_blank'>semantic answers</a> (direct answers to queries that look like a question). In all cases, the responses aren't AI-generated but come directly from the source data."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.QueryType)" id="searchRequest-QueryType-Vector" value="@QueryType.Vector" v-model="searchRequest.queryType" v-bind:disabled="searchRequest.searchIndex == '@SearchIndexType.Documents'">
                        <label class="form-check-label" for="searchRequest-QueryType-Vector">Vector only</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="First send the search query to an <a href='https://learn.microsoft.com/azure/ai-services/openai/how-to/embeddings' target='_blank'>embedding model in Azure OpenAI</a> to generate a vector representing the query itself. Then perform a <a href='https://learn.microsoft.com/azure/search/vector-search-overview' target='_blank'>vector search</a> to retrieve the nearest neighbors in vector space from the chunked and vectorized documents in the <code>Chunks</code> index. This should return results that are semantically similar to the query, as determined by the embedding model's vector representations."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.QueryType)" id="searchRequest-QueryType-HybridStandard" value="@QueryType.HybridStandard" v-model="searchRequest.queryType" v-bind:disabled="searchRequest.searchIndex == '@SearchIndexType.Documents'">
                        <label class="form-check-label" for="searchRequest-QueryType-HybridStandard">Standard hybrid (text + vector)</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Combine the results of a <a href='https://learn.microsoft.com/azure/search/vector-search-overview' target='_blank'>vector search</a> with the regular <a href='https://learn.microsoft.com/azure/search/search-lucene-query-architecture' target='_blank'>full-text search</a> results into a single ranked response."><i class="bi bi-info-circle"></i></span>
                    </div>
                    <div class="form-check form-check-inline">
                        <input class="form-check-input" type="radio" name="@nameof(SearchRequest.QueryType)" id="searchRequest-QueryType-HybridSemantic" value="@QueryType.HybridSemantic" v-model="searchRequest.queryType" v-bind:disabled="searchRequest.searchIndex == '@SearchIndexType.Documents'">
                        <label class="form-check-label" for="searchRequest-QueryType-HybridSemantic">Semantic hybrid (text + vector)</label>
                        <span class="info-tip" data-bs-toggle="popover" data-bs-content="Combine the results of a <a href='https://learn.microsoft.com/azure/search/vector-search-overview' target='_blank'>vector search</a> with <a href='https://learn.microsoft.com/azure/search/semantic-search-overview' target='_blank'>semantic search</a> results into a single ranked response. Compared to standard hybrid search, this provides even more accuracy with L2 reranking using the same language models that power Bing."><i class="bi bi-info-circle"></i></span>
                    </div>
                </div>
            </div>

            <div class="mb-2" v-show="!(searchRequest.engine == '@EngineType.AzureOpenAI' && searchRequest.dataSource == '@DataSourceType.None') && (searchRequest.queryType == '@QueryType.Vector' || searchRequest.queryType == '@QueryType.HybridStandard' || searchRequest.queryType == '@QueryType.HybridSemantic')">
                <label class="form-label">Vector parameters</label>
                <div class="row row-cols-lg-auto g-3 align-items-center">
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Nearest neighbors
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="The number of nearest neighbors to return from vector search. When using semantic search, this should be set to a high enough number in order to get sufficient candidates for semantic reranking."><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="number" class="form-control form-control-small" name="@nameof(SearchRequest.VectorNearestNeighborsCount)" value="@Model.SearchRequest.VectorNearestNeighborsCount" />
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-2" v-show="searchRequest.engine == '@EngineType.CustomOrchestration'">
                <label class="form-label">Model parameters</label>
                <div class="row row-cols-lg-auto g-3 align-items-center">
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Max tokens
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Set a limit on the number of tokens that the model will use to generate the response, to avoid running into token limitations (as token size is counted against the combined prompt and response). One token is roughly 4 characters for typical English text."><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="text" class="form-control form-control-small" name="@nameof(SearchRequest.MaxTokens)" value="@Model.SearchRequest.MaxTokens">
                        </div>
                    </div>
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Temperature
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Controls randomness. Lowering the temperature means that the model will produce more repetitive and deterministic responses. Increasing the temperature will result in more unexpected or creative responses. Try adjusting temperature or <code>Top P</code> but not both. <a href='https://learn.microsoft.com/azure/ai-services/openai/how-to/completions' target='_blank'>Learn more.</a>"><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="text" class="form-control form-control-small" name="@nameof(SearchRequest.Temperature)" value="@Model.SearchRequest.Temperature">
                        </div>
                    </div>
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Top P
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Similar to temperature, this controls randomness but uses a different method. Lowering <code>Top P</code> will narrow the model's token selection to likelier tokens. Increasing <code>Top P</code> will let the model choose from tokens with both high and low likelihood. Try adjusting temperature or <code>Top P</code> but not both. <a href='https://learn.microsoft.com/azure/ai-services/openai/how-to/completions' target='_blank'>Learn more.</a>"><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="text" class="form-control form-control-small" name="@nameof(SearchRequest.TopP)" value="@Model.SearchRequest.TopP">
                        </div>
                    </div>
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Frequency penalty
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Reduce the chance of repeating a token proportionally based on how often it has appeared in the text so far. This decreases the likelihood of repeating the exact same text in a response. <a href='https://platform.openai.com/docs/guides/gpt/parameter-details' target='_blank'>Learn more.</a>"><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="text" class="form-control form-control-small" name="@nameof(SearchRequest.FrequencyPenalty)" value="@Model.SearchRequest.FrequencyPenalty">
                        </div>
                    </div>
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Presence penalty
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Reduce the chance of repeating any token that has appeared in the text at all so far. This increases the likelihood of introducing new topics in a response. <a href='https://platform.openai.com/docs/guides/gpt/parameter-details' target='_blank'>Learn more.</a>"><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="text" class="form-control form-control-small" name="@nameof(SearchRequest.PresencePenalty)" value="@Model.SearchRequest.PresencePenalty">
                        </div>
                    </div>
                    <div class="col-12">
                        <div class="input-group">
                            <div class="input-group-text">
                                Stop sequences
                                <span class="info-tip" data-bs-toggle="popover" data-bs-content="Make the model end its response at a desired point. The model response will end before the specified sequence, so it won't contain the stop sequence text. For ChatGPT, using <code>&lt;|im_end|&gt;</code> ensures that the model response doesn't generate a follow-up user query. You can include as many as four stop sequences, separated by commas."><i class="bi bi-info-circle"></i></span>
                            </div>
                            <input type="text" class="form-control" name="@nameof(SearchRequest.StopSequences)" value="@Model.SearchRequest.StopSequences">
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="card mb-3">
        <div class="card-header">
            <div class="form-check form-check-inline form-switch">
                <input class="form-check-input" type="checkbox" role="switch" v-model="settings.showExplanation">
                <label class="form-check-label">What's going on?</label>
            </div>
        </div>
        <div class="card-body" v-show="settings.showExplanation">
            <pre id="mermaid" class="mermaid"></pre>
        </div>
    </div>

    @if (Model.SearchResponse?.History != null && Model.SearchResponse.History.Any())
    {
        <div class="message-list mb-4">
            @foreach (var item in Model.SearchResponse.History)
            {
                var cssClass = Model.SearchResponse.History.IndexOf(item) % 2 == 0 ? "border-primary-subtle float-end text-end" : "border-info float-start";

                <input type="hidden" name="history[]" value="@item" />
                <div class="message-list-item mt-3 p-2 w-75 border rounded search-answer @cssClass">@Html.Raw(item)</div>
                <div class="clearfix"></div>
            }
        </div>
    }
    else
    {
        if (!string.IsNullOrWhiteSpace(Model.SearchRequest.Query))
        {
            <h3 class="mb-3">Search results for <code>@Model.SearchRequest.Query</code></h3>
        }
    }

    <div class="input-group">
        <input type="text" class="form-control border-primary" placeholder="Search or ask anything" name="@nameof(SearchRequest.Query)" />
        <button class="btn btn-outline-primary" type="submit"><i class="bi bi-send"></i> Send</button>
    </div>
</form>

<partial name="_SearchResponse" model="Model.SearchResponse" />